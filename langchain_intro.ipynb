{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rastringer/promptcraft/blob/main/langchain_intro.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ii3ihksojvA"
      },
      "source": [
        "### LangChain Intro\n",
        "\n",
        "Models, prompt templates and parsers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2k24lCDonBx"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade google-cloud-aiplatform\n",
        "! pip3 install shapely<2.0.0\n",
        "! pip install langchain\n",
        "! pip install pypdf\n",
        "! pip install pydantic==1.10.8\n",
        "! pip install chromadb==0.3.26\n",
        "! pip install langchain[docarray]\n",
        "! pip install typing-inspect==0.8.0 typing_extensions==4.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khvp_6yndlyD"
      },
      "source": [
        "This optional cell wraps outputs, which can make them easier to digest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqKE27cqZBk2"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPxAFOghonE3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hN7KknySjqov"
      },
      "source": [
        "If you're on Colab, authenticate via the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BrhaYTBor1M"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqRMCpihjvxY"
      },
      "source": [
        "Add your project id and the region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAn62-Fcottw"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"<..>\"\n",
        "REGION = \"<...>\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGVFxl9fjt0I"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7Y7McwEz8Zk"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "import time\n",
        "from typing import List\n",
        "\n",
        "# Langchain\n",
        "import langchain\n",
        "from pydantic import BaseModel\n",
        "\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "\n",
        "# Vertex AI\n",
        "from google.cloud import aiplatform\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LogO0tJ9z-73"
      },
      "outputs": [],
      "source": [
        "# LLM model\n",
        "llm = VertexAI(\n",
        "    model_name=\"text-bison@001\",\n",
        "    max_output_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Chat\n",
        "chat = ChatVertexAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lP39CLLa0F2I"
      },
      "outputs": [],
      "source": [
        "chat([HumanMessage(content=\"Hello\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdGjBV420Y6B"
      },
      "outputs": [],
      "source": [
        "res = chat(\n",
        "    [\n",
        "        SystemMessage(\n",
        "            content=\"You are an expert chef that thinks of imaginative recipies when people give you ingredients.\"\n",
        "        ),\n",
        "        HumanMessage(content=\"I have some kidney beans and tomatoes, what would be an easy lunch?\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(res.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiNioRJBeCeU"
      },
      "source": [
        "### Prompt templates\n",
        "\n",
        "Langhain's abstractions such as prompt templates can help keep prompts modular and reusable, especially in large applications which may require long and varied prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSkWubxs1CGM"
      },
      "outputs": [],
      "source": [
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIlbbFVA0agh"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUeNeCwA1BiE"
      },
      "outputs": [],
      "source": [
        "prompt_template.messages[0].prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRYnKpuG0-Zz"
      },
      "outputs": [],
      "source": [
        "prompt_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RzYUX3o1G-D"
      },
      "outputs": [],
      "source": [
        "customer_style = \"\"\"British English, \\\n",
        " respectful tone of a customer service agent.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOYeAk6i1Kky"
      },
      "outputs": [],
      "source": [
        "customer_email = \"\"\"\n",
        "I'm writing this review to express my complete dismay \\\n",
        "and utter horror at the downright disastrous \\\n",
        "coffee maker I purchased from your store. \\\n",
        "It is not at all what I expected. It's a total insult \\\n",
        "to the divine elixir that is coffee!\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwuKkrjL1MP8"
      },
      "outputs": [],
      "source": [
        "customer_messages = prompt_template.format_messages(\n",
        "                    style=customer_style,\n",
        "                    text=customer_email)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ue0mQveh1Nt7"
      },
      "outputs": [],
      "source": [
        "print(type(customer_messages))\n",
        "print(type(customer_messages[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTqCIvvh1PSz"
      },
      "outputs": [],
      "source": [
        "# Call the LLM to translate to the style of the customer message\n",
        "customer_response = chat(customer_messages)\n",
        "print(customer_response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3So1Qbg41Rd0"
      },
      "outputs": [],
      "source": [
        "service_style_glaswegian = \"\"\"\n",
        "A polite assistant that writes in ponetic Glaswegian\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOTjbBru3gx-"
      },
      "outputs": [],
      "source": [
        "service_reply = \"\"\"\n",
        "We're very sorry to read the coffee maker isn't suitable. \\\n",
        "Please come back to the shop, where you can sample some \\\n",
        "brews from the other machines. We offer a refund or exchange \\\n",
        "should you find a better match.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O-ScC1U3Qh4"
      },
      "outputs": [],
      "source": [
        "service_messages = prompt_template.format_messages(\n",
        "    style=service_style_glaswegian,\n",
        "    text=service_reply)\n",
        "\n",
        "print(service_messages[0].content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RdQ9LsegZ2J"
      },
      "source": [
        "Notice when we call the chat model we add an increase to the `temperature` parameter, to allow for more imaginative responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-kxkhuF4GGa"
      },
      "outputs": [],
      "source": [
        "service_response = chat(service_messages, temperature=0.5)\n",
        "print(service_response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSCA8pjmloey"
      },
      "source": [
        "### Why use prompt templates?\n",
        "\n",
        "Prompts can become long and confusing to read in application code, so the level of abstraction templates offer can help reuse material and keep code modular and more understandable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE_nyfIgmKO6"
      },
      "source": [
        "### Parsing outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-karEJ_mtBl"
      },
      "outputs": [],
      "source": [
        "customer_review = \"\"\"\\\n",
        "The excellent barbecue cauliflower starter left \\\n",
        "a lasting impression -- gorgeous presentation and flavors, really geared the tastebuds into action. \\\n",
        "Moving on to the main course, pretty great also. \\\n",
        "Delicious and flavorful chickpea and vegetable curry. They really nailed the buttery consistency, \\\n",
        "depth and balance of the spices. \\\n",
        "The dessert was a bit bland. I opted for a vegan chocolate mousse, \\\n",
        "hoping for a decadent and indulgent finale to my meal. \\\n",
        "It was very visually appealing but was missing the smooth, velvety \\\n",
        "texture of a great mousse.\n",
        "\"\"\"\n",
        "\n",
        "review_template = \"\"\"\\\n",
        "For the input text, extract the following details: \\\n",
        "starter: How did the reviewer find the first course? \\\n",
        "Rate either Poor, Good, or Excellent. \\\n",
        "Do the same for the main course and dessert\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "starter\n",
        "main_course\n",
        "dessert\n",
        "\n",
        "text: {text}\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cp1dMFxkYd5H"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
        "print(prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHoTT2hrXzRj"
      },
      "outputs": [],
      "source": [
        "messages = prompt_template.format_messages(text=customer_review)\n",
        "response = chat(messages, temperature=0.1)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bV8VHzteZsfG"
      },
      "source": [
        "Though it looks like a Python dictionary, our output is actually a string type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT7RLVX9ZYeg"
      },
      "outputs": [],
      "source": [
        "type(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jr6xxJ2ZxQr"
      },
      "source": [
        "This means we are unable to access values in this fashion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16sEr4XhZjHS"
      },
      "outputs": [],
      "source": [
        "response.content.get(\"main_course\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YwKaaROZ1xa"
      },
      "source": [
        "This is where Langchain's parser comes in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1IPczDvZrJp"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "\n",
        "starter_schema = ResponseSchema(name=\"starter\", description=\"Review of the starter\")\n",
        "main_course_schema = ResponseSchema(name=\"main_course\", description=\"Review of the main course\")\n",
        "dessert_schema = ResponseSchema(name=\"dessert\", description=\"Review of the dessert\")\n",
        "\n",
        "response_schemas = [starter_schema, main_course_schema, dessert_schema]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfkKmhhDb5K2"
      },
      "outputs": [],
      "source": [
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4ztjoM8aXF5"
      },
      "outputs": [],
      "source": [
        "format_instructions = output_parser.get_format_instructions()\n",
        "print(format_instructions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpoJt9EpcfKN"
      },
      "source": [
        "Now we can update our prior review template to include the format instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qeh2oItsa5Lu"
      },
      "outputs": [],
      "source": [
        "review_template = \"\"\"\\\n",
        "For the input text, extract the following details: \\\n",
        "starter: How did the reviewer find the first course? \\\n",
        "Rate either Poor, Good, or Excellent. \\\n",
        "Do the same for the main course and dessert\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "starter\n",
        "main_course\n",
        "dessert\n",
        "\n",
        "text: {text}\n",
        "\n",
        "{format_instructions}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4nq3mM8crLn"
      },
      "source": [
        "Let's try it on the same review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_QkXEGscxKX"
      },
      "outputs": [],
      "source": [
        "messages = prompt_template.format_messages(text=customer_review)\n",
        "response = chat(messages, temperature=0.1)\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4EVPQcQcx-_"
      },
      "outputs": [],
      "source": [
        "type(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UslUSpVTczoX"
      },
      "outputs": [],
      "source": [
        "output_dict = output_parser.parse(response.content)\n",
        "output_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWTgsp_rdGq4"
      },
      "outputs": [],
      "source": [
        "type(output_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkEz820ndLGJ"
      },
      "outputs": [],
      "source": [
        "output_dict.get(\"main_course\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15gX9nqvmx7c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM7HjRV6HwQGEq2rsCKusKC",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
