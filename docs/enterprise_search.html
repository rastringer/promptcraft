<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>PromptCraft - 10&nbsp; Enterprise search</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./a_new_hope.html" rel="next">
<link href="./agents_vectorstores.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./langchain_intro.html">Day Two</a></li><li class="breadcrumb-item"><a href="./enterprise_search.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Enterprise search</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">PromptCraft</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/rastringer/promptcraft" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Day One</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./prompting_and_verification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Prompting and verification</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chain_of_thought.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Chain-of-thought-prompting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chaining_prompts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Chaining prompts</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./evaluation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Evaluating outputs</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./day_1_exercise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Day 1 Exercise</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Day Two</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Langchain Intro</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_memory.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Memory</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_chains.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Chains</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./agents_vectorstores.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Agents and vectorstores</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./enterprise_search.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Enterprise search</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./a_new_hope.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Semantic search: Star Wars</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./product_retrieval_llms_embeddings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Deep retrieval with nearest neighbours</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./day_2_exercise.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Day 2 Exercise</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
 <span class="menu-text">Day Three</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./day_3_hackathon.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Day 3 Hackathon</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Enterprise search</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><a href="https://colab.research.google.com/github/rastringer/promptcraft/blob/main/enterprise_search.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a></p>
<p>Using Langchain retrievers with <a href="https://cloud.google.com/enterprise-search">Enterprise Search</a> on Google Cloud.</p>
<p>As of July 2023, the product is available to trusted testers. This notebook offers an example use of retrieving relevant documents for a query.</p>
<p>In this example, we will add course pdfs from Stanfords’s CS224n class, which covers (rather aptly) NLP and LLMs. The dataset is available at <code>gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install <span class="op">--</span>upgrade google<span class="op">-</span>cloud<span class="op">-</span>aiplatform</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install google<span class="op">-</span>cloud<span class="op">-</span>discoveryengine</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install shapely<span class="op">&lt;</span><span class="fl">2.0.0</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install langchain</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install typing<span class="op">-</span>inspect<span class="op">==</span><span class="fl">0.8.0</span> typing_extensions<span class="op">==</span><span class="fl">4.5.0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="3b8c96d1-f321-4ebe-f871-17012ec57360" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Automatically restart kernel after installs so that your environment can access the new packages</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> IPython</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>app <span class="op">=</span> IPython.Application.instance()</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>app.kernel.do_shutdown(<span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>{'status': 'ok', 'restart': True}</code></pre>
</div>
</div>
<p>If you’re on Colab, authenticate via the following cell</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> auth</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>auth.authenticate_user()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Add your <code>project id</code> and the <code>search engine id</code>. The search engine will have to be set up in the Google Cloud console. Future versions of the SDK should provide this feature.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>PROJECT_ID <span class="op">=</span> <span class="st">"&lt;..&gt;"</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>SEARCH_ENGINE_ID <span class="op">=</span> <span class="st">"&lt;..&gt;"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Optional parameters</p>
<p><code>max_documents</code> - The maximum number of documents used to provide extractive segments or extractive answers</p>
<p><code>get_extractive_answers</code> - By default, the retriever is configured to return extractive segments. Set this field to True to return extractive answers</p>
<p><code>max_extractive_answer_count</code> - The maximum number of extractive answers returned in each search result. At most 5 answers will be returned</p>
<p><code>max_extractive_segment_count</code> - The maximum number of extractive segments returned in each search result.</p>
<p><code>filter</code> - Filter the search results based on document metadata in the data store.</p>
<p><code>query_expansion_condition</code> - The conditions under which query expansion should occur. 0 - Unspecified query expansion condition. In this case, server behavior defaults to disabled. 1 - Disabled query expansion. Only the exact search query is used, even if SearchResponse.total_size is zero. 2 - Automatic query expansion built by the Search API.</p>
<div class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.retrievers <span class="im">import</span> GoogleCloudEnterpriseSearchRetriever</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="e315813d-5276-4b61-de4a-353095577ea3" data-execution_count="16">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>retriever <span class="op">=</span> GoogleCloudEnterpriseSearchRetriever(</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    project_id<span class="op">=</span>PROJECT_ID,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    search_engine_id<span class="op">=</span>SEARCH_ENGINE_ID,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    max_documents<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"What are the goals of the course?"</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> retriever.get_relevant_documents(query)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> result:</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(doc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>page_content='[draft] note 1: introduction and word2vec cs 224n: natural language processing with\ndeep learning 3\n\navoid in this course. Partly, this is historical and methodological;\nthe raw signal processing methods and expertise are generally\ncovered in other courses (224s!) and other research communities,\nthough there has been some convergence of techniques of late.\nIn all aspects of NLP, most existing tools work for precious few (usu\nally one, maybe up to 100) of the world’s roughly 7000 languages,\nand fail disproportionately much on lesser-spoken and/or marginal\nized dialects, accents, and more. Beyond this, recent successes in\nbuilding better systems have far outstripped our ability to charac\nterize and audit these systems. Biases encoded in text, from race to\ngender to religion and more, are reflected and often amplified by\nNLP systems. With these challenges and considerations in mind, but\nwith the desire to do good science and build trustworthy systems\nthat improve peoples’ lives, let’s take a look at a fascinating first\nproblem in NLP.\n\n2 Representing words\n2.1 Signifier and signified\nConsider the sentence\n\nZuko makes the tea for his uncle.\n\nThe word Zuko is a sign, a symbol that represents an entity Zuko in\nsome (real of imagined) world. The word tea is also a symbol that\nrefers to a signified thing—perhaps a specific instance of tea. If one\nwere instead to say Zuko likes to make tea for his uncle, note that the\nsymbol Zuko still refers to Zuko, but now tea refers to a broader\nclass—tea in general, not a specific bit of hot delicious water. Consider\nthe two following sentences:\n\nZuko makes the coffee for his uncle.\nZuko makes the drink for his uncle.\n\nWhich is “more like” the sentence about tea? The drink may be tea\n(or it may be quite different!) and coffee definitely isn’t tea, but is yet\nsimilar, no? And is Zuko similar to uncle because they both describe\npeople? And is the similar to his because they both pick out specific\ninstances of a class?\nWord meaning is endlessly complex, deriving from humans’ goals\nof communicating with each other and achieving goals in the world.\nPeople use continuous media—speech, signing—but produce signs\nin a discrete, symbolic structure—language—to express complex\nmeanings. Expressing and processing the nuance and wildness of\nlanguage—while achieving the strong transfer of information that' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/cs224n_winter2023_lecture1_notes_draft.pdf', 'id': '2f84b4522da1ad7216b708405a2e7fd1'}
page_content='cs224n: natural language processing with deep learning lecture notes: part ii\nword vectors ii: glove, evaluation and training 10\n\n3. Apply spherical k-means to cluster these context representations.\n4. Finally, each word occurrence is re-labeled to its associated cluster\nand is used to train the word representation for that cluster.\nFor a more rigorous treatment on this topic, one should refer to\nthe original paper.\n\n3 Training for Extrinsic Tasks\nWe have so far focused on intrinsic tasks and emphasized their\nimportance in developing a good word embedding technique. Of\ncourse, the end goal of most real-world problems is to use the result\ning word vectors for some other extrinsic task. Here we discuss the\ngeneral approach for handling extrinsic tasks.\n3.1 Problem Formulation\n\nMost NLP extrinsic tasks can be formulated as classification tasks.\nFor instance, given a sentence, we can classify the sentence to have\npositive, negative or neutral sentiment. Similarly, in named-entity\nrecognition (NER), given a context and a central word, we want\nto classify the central word to be one of many classes. For the in\nput, "Jim bought 300 shares of Acme Corp. in 2006", we would\nlike a classified output "[Jim]Person bought 300 shares of [Acme\nCorp.]Organization in [2006]Time."\n\nFigure 5: We can classify word vectors\nusing simple linear decision boundaries\nsuch as the one shown here (2-D word\nvectors) using techniques such as\nlogistic regression and SVMs\n\nFor such problems, we typically begin with a training set of the\nform:\n\n{x (i)\n\n, y\n\n(i) }\n\nN\n1\n\nwhere x\n\n(i) is a d-dimensional word vector generated by some word\nembedding technique and y\n(i) is a C-dimensional one-hot vector\nwhich indicates the labels we wish to eventually predict (sentiments,\nother words, named entities, buy/sell decisions, etc.).\nIn typical machine learning tasks, we usually hold input data and\ntarget labels fixed and train weights using optimization techniques\n(such as gradient descent, L-BFGS, Newton’s method, etc.). In NLP\napplications however, we introduce the idea of retraining the input\nword vectors when we train for extrinsic tasks. Let us discuss when\nand why we should consider doing this.\n\nImplementation Tip: Word vector\nretraining should be considered for\nlarge training datasets. For small\ndatasets, retraining word vectors will\nlikely worsen performance.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/cs224n-2019-notes02-wordvecs2.pdf', 'id': '1ff1e859cfb0a87e309c43035be20ec9'}
page_content='2. The Benchmark Tasks\nIn this section, we briefly introduce four standard NLP tasks on which we will benchmark our\narchitectures within this paper: Part-Of-Speech tagging (POS), chunking (CHUNK), Named Entity\nRecognition (NER) and Semantic Role Labeling (SRL). For each of them, we consider a standard\nexperimental setup and give an overview of state-of-the-art systems on this setup. The experimental\nsetups are summarized in Table 1, while state-of-the-art systems are reported in Table 2.\n2.1 Part-Of-Speech Tagging\nPOS aims at labeling each word with a unique tag that indicates its syntactic role, for example, plural\nnoun, adverb, . . .\nA standard benchmark setup is described in detail by Toutanova et al. (2003).\nSections 0–18 of Wall Street Journal (WSJ) data are used for training, while sections 19–21 are for\nvalidation and sections 22–24 for testing.\nThe best POS classifiers are based on classifiers trained on windows of text, which are then fed\nto a bidirectional decoding algorithm during inference. Features include preceding and following\n\n2494' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/collobert11a.pdf', 'id': '3612967ed6bf4badc0bf4808a0b5eada'}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>retriever <span class="op">=</span> GoogleCloudEnterpriseSearchRetriever(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    project_id<span class="op">=</span>PROJECT_ID,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    search_engine_id<span class="op">=</span>SEARCH_ENGINE_ID,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    max_documents<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    max_extractive_answer_count<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    get_extractive_answers<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="bc671c3e-7625-41c6-a3ea-001f82ac74ff" data-execution_count="30">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"Does the course cover transformers?"</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> retriever.get_relevant_documents(query)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> result:</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(doc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>page_content='On faster GPUs, the pretraining can finish in around 30-40 minutes. This assignment is an investigation into Transformer self-attention building blocks, and the effects of pre training. It covers mathematical properties of Transformers and self-attention through written questions.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/a5.pdf:2', 'id': 'e45a23e879587067446c6f876341de6d'}
page_content='2. Pretrained Transformer models and knowledge access (35 points) You&amp;#39;ll train a Transformer to perform a task that involves accessing knowledge about the world — knowledge which isn&amp;#39;t provided via the task&amp;#39;s training data (at least if you want to generalize outside the training set).' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/a5.pdf:2', 'id': 'e45a23e879587067446c6f876341de6d'}
page_content='CS 224N Assignment 5 Page 2 of 10 1.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/a5.pdf:2', 'id': 'e45a23e879587067446c6f876341de6d'}
page_content='Image Transformer of parameters and consequently computational performance and can make training such models more challenging.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/1802.05751.pdf:1', 'id': '0ed0222cb61a3398c75d4df1093e6562'}
page_content='Our best CIFAR-10 model with DMOL has d and feed-forward layer layer dimension of 256 and perform attention in 512 dimensions.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/1802.05751.pdf:1', 'id': '0ed0222cb61a3398c75d4df1093e6562'}
page_content='Training recurrent neural networks to sequentially predict each pixel of even a small image is computationally very challenging.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/1802.05751.pdf:1', 'id': '0ed0222cb61a3398c75d4df1093e6562'}
page_content='In Chapter 10 we explored causal (left-to-right) transformers that can serve as the basis for powerful language models—models that can eas ily be applied to autoregressive generation problems such as contextual generation, summarization and machine translation.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/11.pdf:10', 'id': '26b3bc83d90348c17ebad26a49853226'}
page_content='Every input sentence first has to be tokenized, and then all further processing takes place on subword tokens rather than words.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/11.pdf:10', 'id': '26b3bc83d90348c17ebad26a49853226'}
page_content='11.3.1 Sequence Classification Sequence classification applications often represent an input sequence with a single consolidated representation.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/11.pdf:10', 'id': '26b3bc83d90348c17ebad26a49853226'}</code></pre>
</div>
</div>
<div class="cell" data-outputid="df42797f-1acd-4832-d5ae-32cee3b430fb" data-execution_count="31">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"What is word2vec?"</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> retriever.get_relevant_documents(query)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> doc <span class="kw">in</span> result:</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(doc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>page_content='However, many of the details of word2vec will hold true in methods that we&amp;#39;ll proceed to further in the course, so we&amp;#39;ll focus our time on that. 3.2 Word2vec model and objective The word2vec model represents each word in a fixed vocabulary as a low-dimensional (much smaller than vocabulary size) vector.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/cs224n_winter2023_lecture1_notes_draft.pdf:8', 'id': '2f84b4522da1ad7216b708405a2e7fd1'}
page_content='[draft] note 1: introduction and word2vec cs 224n: natural language processing with deep learning 4 language is intended to achieve—makes representing words an endlessly fascinating problem. Let&amp;#39;s move to some methods. 2.2 Independent words, independent vectors What is a word?' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/cs224n_winter2023_lecture1_notes_draft.pdf:8', 'id': '2f84b4522da1ad7216b708405a2e7fd1'}
page_content='The word2vec model is a probabilistic model specified as follows, where uw refers to the row of U corresponding to word w ∈ V (and likewise for V): pU,V(o|c) = exp u ⊤ o vc ∑w∈V exp u⊤ w vc (4) This may be familiar to you as the softmax function, which takes arbitrary scores (here, one for each word in the vocabulary, resulting from dot products) and produces a probability distribution where larger-scored things get higher probability.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/cs224n_winter2023_lecture1_notes_draft.pdf:8', 'id': '2f84b4522da1ad7216b708405a2e7fd1'}
page_content='Although they learn word embeddings by optimizing over some objective functions using stochastic gradient methods, they have both been shown to be implicitly performing matrix factorizations. Skip-gram Skip-gram Word2Vec maximizes the likelihood of co-occurrence of the center word and context words.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/NeurIPS-2018-on-the-dimensionality-of-word-embedding-Paper.pdf:2', 'id': '55b0877de28706e9b8ec530df0c60fa3'}
page_content='For three popular embedding algorithms: LSA, skip-gram Word2Vec and GloVe, we find their optimal dimensionalities k ∗ that minimize their respective PIP loss. We define the sub-optimality of a particular dimensionality k as the additional PIP loss com pared with k ∗ : EkET k − EET − Ek∗Ek∗ T − EET .' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/NeurIPS-2018-on-the-dimensionality-of-word-embedding-Paper.pdf:2', 'id': '55b0877de28706e9b8ec530df0c60fa3'}
page_content='It states that two embeddings are essentially identical if one can be obtained from the other by performing a unitary operation, eg, a rotation. A unitary operation on a vector corresponds to multiplying the vector by a unitary matrix, ie v = vU, where U TU = UUT = Id.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/NeurIPS-2018-on-the-dimensionality-of-word-embedding-Paper.pdf:2', 'id': '55b0877de28706e9b8ec530df0c60fa3'}
page_content='With word2vec, we train the skip-gram (SG† ) and continuous bag-of-words (CBOW† ) models on the 6 billion token corpus (Wikipedia 2014 + Giga word 5) with a vocabulary of the top 400000 most frequent words and a context window size of 10.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/glove.pdf:10', 'id': '2d92bcf9f62444811e6640154cbe484e'}
page_content='The most important remaining variable to con trol for is training time. For GloVe, the rele vant parameter is the number of training iterations. For word2vec, the obvious choice would be the number of training epochs. Unfortunately, the code is currently designed for only a single epoch:' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/glove.pdf:10', 'id': '2d92bcf9f62444811e6640154cbe484e'}
page_content='We construct a model that utilizes this main ben efit of count data while simultaneously capturing the meaningful linear substructures prevalent in recent log-bilinear prediction-based methods like word2vec.' metadata={'source': 'gs://cloud-samples-data/gen-app-builder/search/stanford-cs-224/glove.pdf:10', 'id': '2d92bcf9f62444811e6640154cbe484e'}</code></pre>
</div>
</div>



</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./agents_vectorstores.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Agents and vectorstores</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./a_new_hope.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Semantic search: Star Wars</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>