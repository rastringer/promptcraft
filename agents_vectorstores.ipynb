{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rastringer/promptcraft/blob/main/agents_vectorstores.ipynb\" target=\"_blank\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ii3ihksojvA"
      },
      "source": [
        "## Agents and vectorstores\n",
        "\n",
        "In this notebook, we will explore one of the most fun features of LangChain: agents and their toolkits.\n",
        "\n",
        "Agents have access to tools such as JSON, Wikipedia, Web Search, GitHub or Pandas Dataframes, and can access their capabilities depending on user input.\n",
        "\n",
        "See [here](https://python.langchain.com/docs/integrations/toolkits/) for a full list of agent toolkits.\n",
        "\n",
        "We will use the following technologies:\n",
        "\n",
        "* Vertex AI Generative Studio\n",
        "\n",
        "* Langchain, a framework for building applications with large language models\n",
        "\n",
        "* The open-source Chroma vector store database\n",
        "\n",
        "## Data Retrieval with LLMs and Embeddings\n",
        "\n",
        "Matching customer queries to products via embeddings and Retrieval Augmentated Generation.\n",
        "\n",
        "### Overview\n",
        "\n",
        "This notebook demonstrates one method of using large language models to interact with data. Using the Wayfair [WANDS](https://www.aboutwayfair.com/careers/tech-blog/wayfair-releases-wands-the-largest-and-richest-publicly-available-dataset-for-e-commerce-product-search-relevance) dataset of more than 42,000 products, we will go through the following steps:\n",
        "\n",
        "* Download the data into a pandas dataframe and take a smaller 1,000-row sample set\n",
        "\n",
        "* Merge then generate embeddings for the product titles and descriptions\n",
        "\n",
        "* Prompt an LLM to retrieve details and relevant documents related to queries.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rc4QMx23Yy0"
      },
      "source": [
        "<img src=\"https://assets.wfcdn.com/im/01139917/resize-h800-w800%5Ecompr-r85/2315/231567967/Capricornus+3+Seater+Sofa.jpg\" width=\"300\"/> <img src=\"https://assets.wfcdn.com/im/07725066/resize-h800-w800%5Ecompr-r85/1584/158440119/Vancasso+BOMOOTIUR+Stoneware+Dinnerware+-+Set+of+18.jpg\" width=\"300\"/>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am33TYRmgTJX"
      },
      "outputs": [],
      "source": [
        "# Install the packages\n",
        "! pip install --upgrade google-cloud-aiplatform\n",
        "! pip install shapely<2.0.0\n",
        "! pip install sentence_transformers\n",
        "! pip install langchain\n",
        "! pip install pypdf\n",
        "! pip install pydantic==1.10.8\n",
        "! pip install chromadb==0.3.26\n",
        "! pip install langchain[docarray]\n",
        "! pip install typing-inspect==0.8.0 typing_extensions==4.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPxAFOghonE3"
      },
      "outputs": [],
      "source": [
        "# Automatically restart kernel after installs so that your environment can access the new packages\n",
        "import IPython\n",
        "\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BrhaYTBor1M"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn8IZiXWgyXz"
      },
      "source": [
        "### SDK and Project Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAn62-Fcottw"
      },
      "outputs": [],
      "source": [
        "#Fill in your GCP project_id and region\n",
        "PROJECT_ID = \"<..>\"\n",
        "REGION = \"<..>\"\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qUJ7u3Ag8nh"
      },
      "source": [
        "### Import Langchain tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHBD6TZGfs8X"
      },
      "outputs": [],
      "source": [
        "# Utils\n",
        "import time\n",
        "from typing import List\n",
        "\n",
        "# Langchain\n",
        "import langchain\n",
        "from pydantic import BaseModel\n",
        "\n",
        "print(f\"LangChain version: {langchain.__version__}\")\n",
        "\n",
        "# Vertex AI\n",
        "from google.cloud import aiplatform\n",
        "from langchain.chat_models import ChatVertexAI\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "print(f\"Vertex AI SDK version: {aiplatform.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMGTzcdKzObI"
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRtvCj3ujmaG"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/wayfair/WANDS/main/dataset/product.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hMTzj13c776"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "product_df = pd.read_csv(\"product.csv\", sep='\\t')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9h90lXfYd28V"
      },
      "outputs": [],
      "source": [
        "product_df = product_df[:1000].dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SymYc7AZsy4w"
      },
      "outputs": [],
      "source": [
        "len(product_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKx6jJe-eAnG"
      },
      "outputs": [],
      "source": [
        "# Reduce the df to columns of interest\n",
        "product_df = product_df.filter([\"product_id\", \"product_name\", \"product_description\", \"average_rating\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S9Ksvsue7o2"
      },
      "outputs": [],
      "source": [
        "product_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kSBTzvr3mQN"
      },
      "source": [
        "### Import and initialize pandas dataframe agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sq2dkLJgzD3_"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_pandas_dataframe_agent\n",
        "from langchain.agents.agent_types import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYxuASfAzNxJ"
      },
      "outputs": [],
      "source": [
        "agent = create_pandas_dataframe_agent(VertexAI(temperature=0), product_df, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJ-hdZnyzVIh"
      },
      "outputs": [],
      "source": [
        "agent.run(\"how many rows are there?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJQoAOKizZZ6"
      },
      "outputs": [],
      "source": [
        "agent.run(\"How many beds are there with a rating of > 4?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pha7BaoYdX0G"
      },
      "outputs": [],
      "source": [
        "agent = create_csv_agent(\n",
        "    VertexAI(temperature=0),\n",
        "    \"data.csv\",\n",
        "    verbose=True,\n",
        "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evzsEp6PdX2j"
      },
      "outputs": [],
      "source": [
        "agent.run(\"How many rows are there?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfMQmWwidX5s"
      },
      "outputs": [],
      "source": [
        "agent.run(\"Do any products descriptions mention polypropylene pile? Output them as JSON please\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwCAtS5yztDs"
      },
      "outputs": [],
      "source": [
        "agent.run(\"What is the square root of all ratings for product names featuring sofas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "205RUlqk0BjS"
      },
      "source": [
        "## Vector stores\n",
        "\n",
        "We will explore embeddings vectors and vector stores in more detail in the subsequent notebooks. Let's see what's possible by concatenating our `product_title` and `product_description` columns and creating a text file from the result. We can then create embeddings and perform various retrieval and Q&A tasks.\n",
        "\n",
        "We will use the open source [Chroma](https://docs.trychroma.com/) vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7JxL6L7gvnT"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import TextLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEgJv8OQiBTc"
      },
      "outputs": [],
      "source": [
        "product_df['text_data'] = product_df['product_name'] + \" \" + product_df['product_description']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZrMGLogjGLA"
      },
      "outputs": [],
      "source": [
        "# Save the \"text_data\" column to a text file\n",
        "text_file_path = \"combined_text_data.txt\"\n",
        "product_df['text_data'].to_csv(text_file_path, sep='\\t', index=False, header=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ISu33RYjRrh"
      },
      "outputs": [],
      "source": [
        "# load the document and split it into chunks\n",
        "loader = TextLoader(\"combined_text_data.txt\")\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RUAKgrszoFeO"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "\n",
        "docs = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZET4JQehoWA3"
      },
      "outputs": [],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pW-ybfYogzY"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "# Clear any previous vector store\n",
        "!rm -rf ./docs/chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SLkQlXTJktyI"
      },
      "outputs": [],
      "source": [
        "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "db = Chroma.from_documents(docs, embedding_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXXU9H04lKWJ"
      },
      "outputs": [],
      "source": [
        "query = \"Is there a slow cooker?\"\n",
        "docs = db.similarity_search(query, n_results=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c6muHP-kJo9"
      },
      "outputs": [],
      "source": [
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa7dWNkzv2A5"
      },
      "outputs": [],
      "source": [
        "query = \"Recommend a durable door mat\"\n",
        "docs = db.similarity_search(query, n_results=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T4erjhUv8uY"
      },
      "outputs": [],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79kVcgDjwHBx"
      },
      "source": [
        "### Retrieval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcbs0BxbqV2o"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "llm = VertexAI(\n",
        "    model_name=\"text-bison@001\",\n",
        "    max_output_tokens=1024,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=db.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d7haWcwrDkG"
      },
      "source": [
        "### Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WvFmNANrEFm"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Build prompt\n",
        "template = \"\"\"Use the following pieces of context to answer the question at the end. \\\n",
        "If you don't know the answer, just say that you don't know, \\\n",
        "don't try to make up an answer. Use three sentences maximum. \\\n",
        "{context}\n",
        "Question: {question}\n",
        "Helpful Answer:\"\"\"\n",
        "QA_CHAIN_PROMPT = PromptTemplate(input_variables=[\"context\", \"question\"],template=template,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5pVrtJBrEct"
      },
      "outputs": [],
      "source": [
        "# Run chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=db.as_retriever(),\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhE2wYNgwu2f"
      },
      "outputs": [],
      "source": [
        "question = \"Can you recommend comfortable bed sheets?\"\n",
        "result = qa_chain({\"query\": question})\n",
        "result[\"result\"]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
